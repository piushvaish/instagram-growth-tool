{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import (NaiveSeasonal, NaiveDrift, Prophet,\n",
    "                          ExponentialSmoothing, ARIMA, AutoARIMA,\n",
    "                          RegressionModel, Theta, FFT)\n",
    "from darts.utils.utils import ModelMode, SeasonalityMode, TrendMode\n",
    "from darts.metrics import mape, mase, r2_score, smape\n",
    "from darts.utils.statistics import check_seasonality, plot_acf, plot_residuals_analysis, extract_trend_and_seasonality\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/later/profile_growth.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TimeSeries, specifying the time and value columns\n",
    "series = TimeSeries.from_dataframe(df, 'Date', 'Followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a training and validation series\n",
    "First, let's split our `TimeSeries` into a training and a validation series. Note: in general, it is also a good practice to keep a test series aside and never touch it until the end of the process. Here, we just build a training and a test series for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation set is for 2 weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = series.split_after(df.shape[0] - 14)#pd.Timestamp('20220214'))\n",
    "train.plot(label='training')\n",
    "val.plot(label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickly try a few more models\n",
    "Let's train a few more and compute their respective MAPE on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "    model.fit(train)\n",
    "    forecast = model.predict(len(val))\n",
    "    print('model {} obtains MAPE: {:.2f}%'.format(model, mape(val, forecast)))\n",
    "\n",
    "\n",
    "eval_model(ExponentialSmoothing())\n",
    "eval_model(Prophet())\n",
    "eval_model(AutoARIMA())\n",
    "eval_model(Theta())\n",
    "eval_model(FFT())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.dataprocessing.transformers import Scaler\n",
    "\n",
    "def eval_model(model):\n",
    "    scaler_dfp = Scaler()\n",
    "    series_dfp_scaled = scaler_dfp.fit_transform(series)\n",
    "    train, val = series_dfp_scaled[:-8], series_dfp_scaled[-8:]\n",
    "    model.fit(train)\n",
    "    forecast = model.predict(len(val))\n",
    "    print('model {} obtains MAPE: {:.2f}%'.format(model, mape(val, forecast)))\n",
    "\n",
    "eval_model(ExponentialSmoothing())\n",
    "eval_model(Prophet())\n",
    "eval_model(AutoARIMA())\n",
    "#eval_model(Theta())\n",
    "eval_model(FFT())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.dataprocessing.transformers import BoxCox\n",
    "from darts.utils.utils import ModelMode, SeasonalityMode, TrendMode\n",
    "\n",
    "\n",
    "def eval_model(model):\n",
    "    BoxCox_dfp = BoxCox()\n",
    "    series_dfp_BoxCox = BoxCox_dfp.fit_transform(series)\n",
    "    train_bx, val_bx = series_dfp_BoxCox.split_after(pd.Timestamp('20220214'))\n",
    "    model.fit(train_bx)\n",
    "    forecast = model.predict(len(val_bx))\n",
    "    print('model {} obtains MAPE: {:.2f}%'.format(model,\n",
    "                                                  mape(val_bx, forecast)))\n",
    "\n",
    "\n",
    "eval_model(ExponentialSmoothing())\n",
    "eval_model(Prophet())\n",
    "eval_model(AutoARIMA())\n",
    "eval_model(Theta(season_mode=SeasonalityMode.ADDITIVE))\n",
    "eval_model(FFT())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we did only built these models with their default parameters. We can probably do better if we fine-tune to our problem. Let's try with the Theta method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch: - FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BoxCox_dfp = BoxCox()\n",
    "series_dfp_BoxCox = BoxCox_dfp.fit_transform(series)\n",
    "\n",
    "fft_model = FFT()\n",
    "parameters = {\n",
    "    'nr_freqs_to_keep': np.arange(start=1, stop=20),\n",
    "    'trend': ['poly', 'exp'],\n",
    "    'trend_poly_degree': np.arange(start=1, stop=20)\n",
    "}\n",
    "fft_model.gridsearch(parameters,\n",
    "                     series_dfp_BoxCox,\n",
    "                     last_points_only=True,\n",
    "                     metric=smape,\n",
    "                     forecast_horizon=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fft_model = FFT(nr_freqs_to_keep=7, trend='poly', trend_poly_degree=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BoxCox_dfp = BoxCox()\n",
    "series_dfp_BoxCox = BoxCox_dfp.fit_transform(series)\n",
    "train_bx, val_bx = series_dfp_BoxCox.split_after(df.shape[0] - 14)#split_after(pd.Timestamp('20210131'))\n",
    "fft_model.fit(train_bx)\n",
    "preds = fft_model.predict(len(val_bx))\n",
    "print('model {} obtains MAPE: {:.2f}%'.format(fft_model, mape(val_bx, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = BoxCox_dfp.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.plot(label='train')\n",
    "val.plot(label='true')\n",
    "forecast.plot(label='prediction')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the model with `best_theta` is so far the best we have, in terms of MAPE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting: simulate historical forecasting\n",
    "So at this point we have a model that performs well on our validation set, and that's good. But how can we know the performance we *would have obtained* if we *had been using this model* historically. \n",
    "\n",
    "Backtesting simulates predictions that would have been obtained historically with a given model. It can take a while to produce, since the model is re-fit every time the simulated prediction time advances.\n",
    "\n",
    "Such simulated forecasts are always defined with respect to a *forecast horizon*, which is the number of time steps that separate the prediction time from the forecast time. In the example below, we simulate forecasts done for 3 months in the future (compared to prediction time).\n",
    "\n",
    "Using the `backtest()` method, you can either look at the performance of the model evaluated over the whole forecasts it produces (each point in each forecast is used to compute an error score) or only the last point of each historical forecast.\n",
    "In the latter case, you can get a time series representation of those points by calling `historical_forecasts()` with the default setting (`last_points_only=True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install ipywidgets\n",
    "#!jupyter nbextension enable --py widgetsnbextension\n",
    "#from ipywidgets import FloatProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "average_error = fft_model.backtest(series_dfp_BoxCox,\n",
    "                                   start=pd.Timestamp('20220226'),\n",
    "                                   forecast_horizon=2,\n",
    "                                   metric=smape,\n",
    "                                   last_points_only=True,\n",
    "                                   verbose=True)\n",
    "median_error = fft_model.backtest(series_dfp_BoxCox,\n",
    "                                  start=pd.Timestamp('20220226'),\n",
    "                                  forecast_horizon=2,\n",
    "                                  metric=smape,\n",
    "                                  last_points_only=True,\n",
    "                                  reduction=np.median,\n",
    "                                  verbose=True)\n",
    "print(\"Average error (MAPE) over all historical forecasts: {}\".format(\n",
    "    average_error))\n",
    "print(\"Median error (MAPE) over all historical forecasts: {}\".format(\n",
    "    median_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_errors = fft_model.backtest(series_dfp_BoxCox,\n",
    "                                start=pd.Timestamp('20220226'),\n",
    "                                forecast_horizon=2,\n",
    "                                metric=smape,\n",
    "                                last_points_only=True,\n",
    "                                reduction=None,\n",
    "                                verbose=True)\n",
    "\n",
    "plt.hist(raw_errors)\n",
    "plt.title(\"Individual error scores (histogram)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "historical_fcast_fft = fft_model.historical_forecasts(\n",
    "    series_dfp_BoxCox,\n",
    "    start=pd.Timestamp('20220226'),\n",
    "    forecast_horizon=2,\n",
    "    last_points_only=True,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_fcast_fft['0'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what this backtest forecast looks like. You can see it produces more accurate predictions at a 3 months horizon than the one-off prediction done above, because here the model is re-fit every month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_dfp_BoxCox.plot(label='data')\n",
    "historical_fcast_fft.plot(label='backtest 2-months ahead forecast (FFT)')\n",
    "plt.title('MAPE = {:.2f}%'.format(mape(historical_fcast_fft,\n",
    "                                       series_dfp_BoxCox)))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the fitted value residuals of our current `Theta` model, i.e. the difference between the 1-step forecasts at every point in time obtained by fitting the model on all previous points, and the actual observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals_analysis(fft_model.residuals(series_dfp_BoxCox))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the distribution has a mean that is slightly larger than 0. This means that our `Theta` model is biased. We can also make out a large ACF value at lag equal to 12, which indicates that the residuals contain information that was not used by the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Theta()\n",
    "parameters = {\n",
    "    'theta': 2 - np.linspace(-10, 10, 50),\n",
    "    'seasonality_period': [7, 14, 21],\n",
    "    'season_mode': [SeasonalityMode.ADDITIVE],\n",
    "}\n",
    "model.gridsearch(parameters,\n",
    "                 series_dfp_BoxCox,\n",
    "                 metric=smape,\n",
    "                 forecast_horizon=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_theta_model = Theta(theta=5.877551020408163,\n",
    "                         seasonality_period=21,\n",
    "                         season_mode=SeasonalityMode.ADDITIVE)\n",
    "best_theta_model.fit(train_bx)\n",
    "pred_best_theta = best_theta_model.predict(len(val_bx))\n",
    "\n",
    "print('The MAPE is: {:.2f}.'.format(mape(val_bx, pred_best_theta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bx.plot(label='train')\n",
    "val_bx.plot(label='true')\n",
    "pred_best_theta.plot(label='prediction', figsize=(15, 4))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residual analysis also reflects an improved performance in that we now have a distribution of the residuals centred at value 0, and the ACF values, although not insignificant, have lower magnitudes.\n",
    "\n",
    "## Ensembling several predictions\n",
    "*Ensembling* is about combining the forecasts produced by several models, in order to obtain a final -- and hopefully better forecast.\n",
    "\n",
    "For instance, in our example of a \"less naive\" model above, we manually combined a naive seasonal model with a naive drift model. Here, we will try to find such combinations in an automated way, using `RegressionModel`s. A regression model is a model that predicts a *target* time series from a bunch of *features* time series. If the features time series are themselves obtained from forecasting models, their future (predicted) values can be combined using the regression model to obtain a final forecast.\n",
    "\n",
    "Here, we will first compute the historical predictions two naive seasonal models (with 6 and 12 months seasonality), and naive drift model. To compute the historical forecasts, we can simply reuse the `historical_forecasts()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    FFT(nr_freqs_to_keep=7, trend='poly', trend_poly_degree=4),\n",
    "    Theta(theta=5.877551020408163,\n",
    "          seasonality_period=21,\n",
    "          season_mode=SeasonalityMode.ADDITIVE),\n",
    "    AutoARIMA()\n",
    "]\n",
    "\n",
    "model_predictions = [\n",
    "    m.historical_forecasts(series_dfp_BoxCox,\n",
    "                           start=pd.Timestamp('20201201'),\n",
    "                           forecast_horizon=2,\n",
    "                           last_points_only=True,\n",
    "                           verbose=True) for m in models\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" \n",
    "We build the regression model, and tell it to use the 12 preceding points to fit the regression\n",
    "\"\"\"\n",
    "regr_model = StandardRegressionModel(train_n_points=14)#, model = neigh )\n",
    "\"\"\" \n",
    "Our target series is what we want to predict (the actual data)\n",
    "    \n",
    "    It has to have the same time index as the features series:\n",
    "\"\"\"\n",
    "series_target = series_dfp_BoxCox.slice_intersect(model_predictions[0])\n",
    "\"\"\" \n",
    "Here we backtest our regression model\n",
    "\"\"\"\n",
    "ensemble_pred = regr_model.historical_forecasts(model_predictions,\n",
    "                                                series_target,\n",
    "                                                start=pd.Timestamp('20201203'),\n",
    "                                                forecast_horizon=2,\n",
    "                                                last_points_only=True,\n",
    "                                                verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see how good the regression performs, compared to the original forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "series[100:].plot(label='actual')\n",
    "# for i, m in enumerate(models):\n",
    "#     BoxCox_dfp.inverse_transform(model_predictions[i]).plot(label=str(m))\n",
    "\n",
    "#     # intersect last part, to compare all the methods over the duration of the ensemble forecast\n",
    "#     model_pred = model_predictions[i].slice_intersect(ensemble_pred)\n",
    "\n",
    "#     mape_model = mape(series, model_pred)\n",
    "#     print('MAPE Error for {}: {:.2f}%'.format(m, mape_model))\n",
    "\n",
    "print('MAPE Error ensemble: {:.2f}%'.format(mape(series, ensemble_pred)))\n",
    "\n",
    "BoxCox_dfp.inverse_transform(ensemble_pred).plot(label='Ensemble')\n",
    "\n",
    "print('\\nCoefficients of the features time series:')\n",
    "for i, m in enumerate(models):\n",
    "    print('Learned coefficient for {}: {:.2f}'.format(\n",
    "        m, regr_model.model.coef_[0][i]))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = TimeSeries.pd_dataframe(BoxCox_dfp.inverse_transform(ensemble_pred))\n",
    "predictions.columns = ['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TimeSeries.pd_dataframe(series.split_after(pd.Timestamp('20201203'))[1][:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "error = (predictions['Label'] - test['Count']).astype('int').to_frame()\n",
    "error.columns = ['errors']\n",
    "errors_mean = error['errors'].mean()\n",
    "errors_std = error['errors'].std()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "\n",
    "sns.distplot(a=error['errors'], ax=ax, bins=15, rug=True)\n",
    "ax.axvline(x=errors_mean, color='b', linestyle='--', label=r'$\\mu$')\n",
    "ax.axvline(x=errors_mean + 2 * errors_std,\n",
    "           color='r',\n",
    "           linestyle='--',\n",
    "           label=r'$\\mu \\pm 2\\sigma$')\n",
    "ax.axvline(x=errors_mean - 2 * errors_std, color='k', linestyle='--')\n",
    "ax.legend()\n",
    "ax.set(title='Model Errors');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8, 6))\n",
    "plot_acf(x=error['errors'], ax=ax[0]),\n",
    "plot_pacf(x=error['errors'], ax=ax[1]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instagram-growth-strategy",
   "language": "python",
   "name": "instagram-growth-strategy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
