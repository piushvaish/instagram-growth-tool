{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b711b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neigh = KNeighborsRegressor(n_neighbors=2)\n",
    "\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import (NaiveSeasonal, NaiveDrift, Prophet,\n",
    "                          ExponentialSmoothing, ARIMA, AutoARIMA,\n",
    "                          RegressionModel, Theta, FFT)\n",
    "from darts.utils.utils import ModelMode, SeasonalityMode, TrendMode\n",
    "from darts.metrics import mape, mase, r2_score, smape\n",
    "from darts.utils.statistics import check_seasonality, plot_acf, plot_residuals_analysis, extract_trend_and_seasonality\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3966f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/later/profile_growth.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "# Create a TimeSeries, specifying the time and value columns\n",
    "series = TimeSeries.from_dataframe(df, 'Date', 'Followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8c2985",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "series.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a364dfa2",
   "metadata": {},
   "source": [
    "### Creating a training and validation series\n",
    "First, let's split our TimeSeries into a training and a validation series. Note: in general, it is also a good practice to keep a test series aside and never touch it until the end of the process. Here, we just build a training and a test series for simplicity.\n",
    "\n",
    "#### Validation - 2 weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b417893",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "train, val = series.split_after(df.shape[0] - 14)#pd.Timestamp('20220214'))\n",
    "train.plot(label='training')\n",
    "val.plot(label='validation')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e88971",
   "metadata": {},
   "source": [
    "### Quickly try a few more models\n",
    "Let's train a few more and compute their respective MAPE on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f262c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "    model.fit(train)\n",
    "    forecast = model.predict(len(val))\n",
    "    print('model {} obtains MAPE: {:.2f}%'.format(model, mape(val, forecast)))\n",
    "    plt.title(\"MAPE = {:.2f}%\".format(mape(forecast, val)))\n",
    "    series.plot(label=\"actual\")\n",
    "    forecast.plot(label=f\"{model}:forecast\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "eval_model(ExponentialSmoothing())\n",
    "eval_model(Prophet())\n",
    "eval_model(AutoARIMA())\n",
    "eval_model(Theta())\n",
    "eval_model(FFT())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19878a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoARIMA()\n",
    "model.fit(train)\n",
    "forecast = model.predict(len(val))\n",
    "\n",
    "print('model {} obtains MAPE: {:.2f}%'.format(model, mape(val, forecast)))\n",
    "\n",
    "series.plot(label=\"actual\")\n",
    "forecast.plot(label=\"forecast\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c73558",
   "metadata": {},
   "source": [
    "### Scaled\n",
    "\n",
    "Normalize the time series (note: we avoid fitting the transformer on the validation set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddeef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.dataprocessing.transformers import Scaler\n",
    "transformer = Scaler()\n",
    "train_transformed = transformer.fit_transform(train)\n",
    "val_transformed = transformer.transform(val)\n",
    "series_transformed = transformer.transform(series)\n",
    "\n",
    "model = AutoARIMA()\n",
    "model.fit(train_transformed)\n",
    "preds = model.predict(len(val_transformed))\n",
    "\n",
    "forecast = transformer.inverse_transform(preds)\n",
    "\n",
    "print('model {} obtains MAPE: {:.2f}%'.format(model, mape(val, forecast)))\n",
    "\n",
    "series.plot(label=\"actual\")\n",
    "forecast.plot(label=f\"{model}:forecast\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f52ca8",
   "metadata": {},
   "source": [
    "### Box Cox Transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac1db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.dataprocessing.transformers import BoxCox\n",
    "from darts.utils.utils import ModelMode, SeasonalityMode, TrendMode\n",
    "\n",
    "\n",
    "transformer_boxcox = BoxCox()\n",
    "train_transformed = transformer_boxcox.fit_transform(train)\n",
    "val_transformed = transformer_boxcox.transform(val)\n",
    "series_transformed = transformer_boxcox.transform(series)\n",
    "\n",
    "model = AutoARIMA()\n",
    "model.fit(train_transformed)\n",
    "preds = model.predict(len(val_transformed))\n",
    "\n",
    "forecast = transformer.inverse_transform(preds)\n",
    "\n",
    "print('model {} obtains MAPE: {:.2f}%'.format(model, mape(val, forecast)))\n",
    "\n",
    "series.plot(label=\"actual\")\n",
    "forecast.plot(label=f\"{model}:forecast\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b38c0",
   "metadata": {},
   "source": [
    "### Backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b9e59",
   "metadata": {},
   "source": [
    "Compute error values that the model would have produced when used on series.\n",
    "\n",
    "It repeatedly builds a training set from the beginning of series. It trains the current model on the training set, emits a forecast of length equal to forecast_horizon, and then moves the end of the training set forward by stride time steps. A metric (given by the metric function) is then evaluated on the forecast and the actual values. Finally, the method returns a reduction (the mean by default) of all these metric scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5308e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "days_to_subtract = 14\n",
    "start_timestamp = df['Date'].max() - timedelta(days=days_to_subtract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1450c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_error = model.backtest(series,\n",
    "                               start= start_timestamp,\n",
    "                               forecast_horizon=1,\n",
    "                               metric=mape,\n",
    "                               last_points_only=True,\n",
    "                               verbose=True)\n",
    "print(\"Average error (MAPE) over all historical forecasts: {}\".format(\n",
    "    average_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_error = model.backtest(series,\n",
    "                                  start=start_timestamp,\n",
    "                                  forecast_horizon=1,\n",
    "                                  metric=mape,\n",
    "                                  last_points_only=True,\n",
    "                                  reduction=np.median,\n",
    "                                  verbose=True)\n",
    "\n",
    "print(\"Median error (MAPE) over all historical forecasts: {}\".format(\n",
    "    median_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba72a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_errors = model.backtest(series,\n",
    "                                start=start_timestamp,\n",
    "                                forecast_horizon=1,\n",
    "                                metric=mape,\n",
    "                                last_points_only=True,\n",
    "                                reduction=None,\n",
    "                                verbose=True)\n",
    "\n",
    "plt.hist(raw_errors)\n",
    "plt.title(\"Individual error scores (histogram)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b832f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_fcast = model.historical_forecasts(\n",
    "    series,\n",
    "    start=start_timestamp,\n",
    "    forecast_horizon=7,\n",
    "    last_points_only=True,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb2385f",
   "metadata": {},
   "source": [
    "Let's see what this backtest forecast looks like. \n",
    "\n",
    "You can see it produces more accurate predictions at a 1 day horizon than the one-off prediction (7 days) done above, because here the model is re-fit every day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca575da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "series.plot(label='data')\n",
    "historical_fcast.plot(label='backtest 3-days ahead forecast')\n",
    "plt.title('MAPE = {:.2f}%'.format(mape(historical_fcast,\n",
    "                                       series)))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fb3361",
   "metadata": {},
   "source": [
    "Let's look at the fitted value residuals of our current `Auto Arima` model, i.e. the difference between the 1-step forecasts at every point in time obtained by fitting the model on all previous points, and the actual observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de275190",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals_analysis(model.residuals(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b209a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.residuals(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08863691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.utils.statistics import plot_hist\n",
    "plot_hist(model.residuals(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058e2953",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef47e88",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc673ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = TimeSeries.pd_dataframe(forecast)\n",
    "predictions.columns = ['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b892ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['Label'] = np.round(predictions['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f4244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "error = (predictions['Label'] - test['Followers']).astype('int').to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94abfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TimeSeries.pd_dataframe(val)\n",
    "test.columns = ['Followers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc75366",
   "metadata": {},
   "outputs": [],
   "source": [
    "error.columns = ['errors']\n",
    "errors_mean = error['errors'].mean()\n",
    "errors_std = error['errors'].std()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "\n",
    "sns.distplot(a=error['errors'], ax=ax, bins=15, rug=True)\n",
    "ax.axvline(x=errors_mean, color='b', linestyle='--', label=r'$\\mu$')\n",
    "ax.axvline(x=errors_mean + 2 * errors_std,\n",
    "           color='r',\n",
    "           linestyle='--',\n",
    "           label=r'$\\mu \\pm 2\\sigma$')\n",
    "ax.axvline(x=errors_mean - 2 * errors_std, color='k', linestyle='--')\n",
    "ax.legend()\n",
    "ax.set(title='Model Errors');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17021d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8, 6))\n",
    "plot_acf(x=error['errors'], ax=ax[0]),\n",
    "#plot_pacf(x=error['errors'], ax=ax[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c24687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instagram-growth-strategy",
   "language": "python",
   "name": "instagram-growth-strategy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
